---
name: Book
description: "Orchestrate the full workflow of restructuring a PDF book into analysis-ready markdown documents"
argument-hint: '{source} "{instructions}" - PDF file path and optional restructuring instructions'
allowed-tools: Task, Bash, Read, Skill
skills: Prepare_Book, Describe_Images, Restructure
model: opus
timeout: 600000
---

# Book Architect Command

Transform PDF books into well-organized prose documents through complete agent delegation.

**Parameters**: `$ARGUMENTS` = `{source}` (PDF path) + optional `"{instructions}"` (style/language)

**Example**: `/Book TMP/Value.pdf` or `/Book TMP/Value.pdf "Korean informal style"`

---

## Core Principles

1. **Orchestrator Only**: Main command does NOT read markdown content (only toc.json for planning)
2. **Skill Delegation**: Prepare_Book for PDF ops, Restructure for content transformation
3. **Rate-limited Execution**: Sequential processing with delays to prevent API rate limits
4. **Zero Information Loss**: Agents preserve all original content

**Tool Usage**:
- `Skill()`: Invoke Prepare_Book for PDF preparation
- `Bash()`: File verification, discovery, script execution
- `Read()`: ONLY for toc.json (the only file main command reads directly)

---

## Variable Definitions

**CRITICAL**: Define these variables at Phase 1 completion and use them consistently throughout all phases.

| Variable | Source | Example |
|----------|--------|---------|
| `VAULT_PATH` | Vault root (absolute, auto-detected) | `$(pwd)` at command start |
| `BOOK_FOLDER` | toc.json's parent directory (absolute) | `/Users/.../üö®Temporary/üìñBooks/üìïÌòêÏò§/HATE` |
| `BOOK_NAME` | Folder name extracted from BOOK_FOLDER | `HATE` |

**Extract from toc.json path**:
```bash
# After Prepare_Book outputs: "Ï†ÄÏû•Îê®: /path/to/HATE/toc.json"
BOOK_FOLDER="/path/to/HATE"  # Parent directory of toc.json
BOOK_NAME="HATE"             # Basename of BOOK_FOLDER
VAULT_PATH="$(pwd)"  # Auto-detect vault root at command start
```

**Set `VAULT_PATH="$(pwd)"` ONCE at command start** - then use `$VAULT_PATH` for all subsequent references. Never re-evaluate `$(pwd)` after cd commands.

---

## Phase Execution

### Phase 1: PDF Preparation

1. **Verify PDF**: `ls "{source}"` - exit if not found
2. **Invoke Prepare_Book skill**: Handles TOC analysis, PDF splitting, markdown conversion
3. **Read toc.json**: Understand book structure for orchestration
4. **Set variables immediately after reading toc.json**:
```bash
# Extract from toc.json's pdf_path or the "Ï†ÄÏû•Îê®:" output path
VAULT_PATH="$(pwd)"  # Auto-detect vault root at command start
BOOK_FOLDER="/absolute/path/to/book_folder"  # e.g., from toc.json location
BOOK_NAME="book_name"  # basename of BOOK_FOLDER
```

**Output structure**:
```
{book_name}/
	toc.json, {chapter}.pdf, {chapter}.md, image-cache_{chapter}.json, images/
```

### Phase 1.5: Image Description

**Single Bash() call** with sequential processing (special characters safe):
```bash
find "$BOOK_FOLDER" -maxdepth 1 -name "*.md" -type f -not -name "*.backup*" -print0 | \
	sort -zV | while IFS= read -r -d '' file; do
		echo "Processing: $file"
		(cd "<Describe_Images_skill>/Scripts" && \
			source .venv/bin/activate && \
			python Describe_Images.py "$file")
	done
```

- Uses `-print0` and `read -d ''` for special character safety (`"`, `'` in filenames)
- Sequential processing prevents API rate limit issues
- Subshell `(...)` preserves working directory

### Phase 2: Content Restructuring

**Single Bash() call** with batch script (10-second intervals for API rate limit):
```bash
"<Restructure_skill>/scripts/batch.sh" "$BOOK_FOLDER" "{additional_prompt}"
```
- **Use `$VAULT_PATH` and `$BOOK_FOLDER` variables** (set in Phase 1)
- Processes files in ascending filename order (`sort -V`)
- 10-second delay between files prevents API rate limit
- Optional: pass additional prompt as second argument

**Output**: `Restructured_{chapter}.md` (auto-generated by script)

### Phase 2.1: Restructuring Validation

**Goal**: Detect chapters where Gemini abnormally truncated content.

**Method**: Compare character counts between original `{chapter}.md` and `Restructured_{chapter}.md`, print comparison table:

| # | Chapter | Original (chars) | Restructured (chars) | Ratio |
|---|---------|------------------:|---------------------:|------:|

- **Threshold**: ratio < 35% ‚Üí abnormal (normal range ~45-55%)
- **Anomaly detected** ‚Üí `AskUserQuestion()` to confirm reprocessing flagged chapters
  - If approved: re-run `restructure.sh` per flagged file (10s intervals) ‚Üí re-validate
- **No anomalies** ‚Üí proceed to Phase 2.5

### Phase 2.5: Heading Normalization

**Goal**: Normalize heading hierarchy, replace first heading with toc title, add ancestor headings for first children.

#### Level Normalization (required for all books)

Gemini outputs inconsistent heading levels per file. Always normalize:

1. **First heading level = split level**
   - split --level 1 ‚Üí first heading = `#` (h1)
   - split --level 2 ‚Üí first heading = `##` (h2)
   - split --level 3 ‚Üí first heading = `###` (h3)
2. **First heading title = toc.json entry title** for that file
3. **Remaining headings must be deeper than first heading by at least one level**
   - shift = min(remaining heading levels) - (split_level + 1)
   - new_level = old_level - shift (floor = split_level + 1)
4. **Preserve relative depth**: depth differences between headings within a file are maintained

Code pattern:
```python
split_level = 1  # from Prepare_Book --level argument
for each Restructured file:
    first_heading ‚Üí "#" * split_level + " " + toc_title
    other_headings:
        target_min = split_level + 1  # e.g., 2 for split_level=1
        actual_min = min(other heading levels)
        shift = actual_min - target_min
        new_level = old_level - shift (min = target_min)
```

#### Ancestor Heading Algorithm

1. **Parse toc.json** ‚Üí build parent-child relationships
2. **First child detection**: Entry is first child if it's the first at that level after parent
3. **Ancestor chain**: If first child, trace upward collecting ancestors (also first children)
4. **Per-file normalization**:
	- Add ancestor headings (e.g., `# Part I` before `## 3. Chapter Title`)
	- First heading = `{#level} {toc_title}`
	- Subsequent headings deeper than first

**Example** (split at level=2):
```
Part I (level 1) ‚Üê parent
	‚îú‚îÄ 3. One Person's... (level 2) ‚Üê FIRST CHILD ‚Üí prepend "# Part I"
	‚îî‚îÄ 4. Another Chapter (level 2) ‚Üê not first child
```

Result for `Restructured_3. One Person's...md`:
```markdown
# Part I: Liberty and Freedom

## 3. One Person's Freedom Is Another Person's Unfreedom
```

**Execution Method**: Use `Bash()` with heredoc - NO temporary py files
```bash
python3 << 'EOF'
import json, glob, re
# LLM generates situation-specific code here
# ... toc parsing, file matching, heading normalization ...
EOF
```
- DO NOT create temporary .py files
- Write Python code directly inside Bash() heredoc
- LLM adapts code to each book's specific structure

### Phase 3: Merge

1. **Find files**: `find "$BOOK_FOLDER" -maxdepth 1 -name "Restructured_*.md" | sort -V`
2. **Merge with Python**: glob ‚Üí numeric sort ‚Üí join with 5 blank lines
3. **Output**: `$BOOK_FOLDER/Merge_$BOOK_NAME.md`
- **Use `$BOOK_FOLDER` and `$BOOK_NAME` variables** (set in Phase 1)

### Phase 4: Results Summary

Output markdown summary: source PDF, chapters processed, file mapping, merged document path.

---

## Critical Constraints

These constraints prevent unrecoverable errors:

1. **Main command MUST NOT Read() markdown files** - only toc.json allowed
2. **Rate-limited batch processing** - use batch.sh with 10-second delays for API rate limit
3. **Set `VAULT_PATH="$(pwd)"` ONCE at Phase 1** - then use `$VAULT_PATH`, `$BOOK_FOLDER`, `$BOOK_NAME` variables consistently; never re-evaluate `$(pwd)` after cd commands
4. **Use `-print0 | while read -d ''`** for file iteration - handles special characters (`"`, `'`) in filenames safely
5. **Wait for Bash() completion** before next phase - file existence ‚â† content complete
6. **Use Python file I/O** - macOS unicode (NFC vs NFD) breaks Edit tool on Korean paths
7. **Use `sort -V`** for file ordering - alphabetic sort puts "10" before "2"
8. **No AskUserQuestion at completion** - user provides feedback if needed (Phase 2.1 validation is the only exception where `AskUserQuestion()` is used)

---

## Error Handling

| Error | Solution |
|-------|----------|
| Source PDF not found | Verify path with `ls` |
| No TOC in PDF | PDF needs embedded TOC (Adobe Acrobat) |
| Markdown conversion failed | Check TMP/PDF_to_MD/.env API keys |
| Restructuring failed | Check `which gemini`, API quota, UTF-8 encoding |
| venv issues | `rm -rf venv && python3 -m venv venv && pip install -r requirements.txt` |

---

## Quick Reference

| Scenario | Command |
|----------|---------|
| Full processing | `/Book TMP/Value.pdf` |
| Korean style | `/Book TMP/Book.pdf "Korean informal style"` |
| Custom style | `/Book TMP/Book.pdf "academic formal style"` |

**Output Structure**:
```
{book_name}/
	toc.json
	{chapter}.pdf / .md / image-cache_{chapter}.json
	Restructured_{chapter}.md
	Merge_{book_name}.md
	images/
```

---

## Execution Directive

Execute immediately in sequence:

1. Parse `$ARGUMENTS` ‚Üí source PDF path + optional instructions
2. Verify PDF exists (`ls`)
3. Invoke Prepare_Book skill, wait for completion
4. Read toc.json (only file to read directly)
5. **Set variables immediately** (CRITICAL - before any subsequent phase):
```bash
VAULT_PATH="$(pwd)"  # Auto-detect vault root at command start
BOOK_FOLDER="<absolute path from toc.json location>"
BOOK_NAME="<basename of BOOK_FOLDER>"
```
6. Phase 1.5: Single Bash() with `find -print0 | while read` for sequential processing
7. Phase 2: Single Bash() with batch.sh using `$VAULT_PATH` and `$BOOK_FOLDER`
8. Phase 2.1: Validation table ‚Üí if anomalies, `AskUserQuestion()` ‚Üí reprocess flagged chapters
9. Phase 2.5: Heading normalization with Python heredoc using `$BOOK_FOLDER`
10. Phase 3: Merge with Python using `$BOOK_FOLDER` and `$BOOK_NAME`
11. Output results summary (no AskUserQuestion)