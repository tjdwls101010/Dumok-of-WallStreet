---
name: Book
description: "Orchestrate the full workflow of restructuring a PDF book into analysis-ready markdown documents"
argument-hint: '{source} "{instructions}" - PDF file path and optional restructuring instructions'
allowed-tools: Task, Bash, Read, Skill
skills: Prepare_Book, Describe_Images, Restructure
model: sonnet
timeout: 600000
---

# Book Architect Command

Transform PDF books into well-organized prose documents through complete agent delegation.

**Parameters**: `$ARGUMENTS` = `{source}` (PDF path) + optional `"{instructions}"` (style/language)

**Example**: `/Book TMP/Value.pdf` or `/Book TMP/Value.pdf "Korean informal style"`

---

## Core Principles

1. **Orchestrator Only**: Main command does NOT read markdown content (only toc.json for planning)
2. **Skill Delegation**: Prepare_Book for PDF ops, Restructure for content transformation
3. **Rate-limited Execution**: Sequential processing with delays to prevent API rate limits
4. **Zero Information Loss**: Agents preserve all original content

**Tool Usage**:
- `Skill()`: Invoke Prepare_Book for PDF preparation
- `Bash()`: File verification, discovery, script execution
- `Read()`: ONLY for toc.json (the only file main command reads directly)

---

## Variable Definitions

**CRITICAL**: Define these variables at Phase 1 completion and use them consistently throughout all phases.

| Variable | Source | Example |
|----------|--------|---------|
| `VAULT_PATH` | Vault root (absolute) | `/Users/seongjin/Documents/‚≠êÏÑ±ÏßÑÏù¥Ïùò ÏòµÏãúÎîîÏñ∏` |
| `BOOK_FOLDER` | toc.json's parent directory (absolute) | `/Users/.../üö®Temporary/üìñBooks/üìïÌòêÏò§/HATE` |
| `BOOK_NAME` | Folder name extracted from BOOK_FOLDER | `HATE` |

**Extract from toc.json path**:
```bash
# After Prepare_Book outputs: "Ï†ÄÏû•Îê®: /path/to/HATE/toc.json"
BOOK_FOLDER="/path/to/HATE"  # Parent directory of toc.json
BOOK_NAME="HATE"             # Basename of BOOK_FOLDER
VAULT_PATH="/Users/seongjin/Documents/‚≠êÏÑ±ÏßÑÏù¥Ïùò ÏòµÏãúÎîîÏñ∏"
```

**NEVER use `$(pwd)`** - working directory may be polluted by previous commands. Always use absolute paths stored in variables.

---

## Phase Execution

### Phase 1: PDF Preparation

1. **Verify PDF**: `ls "{source}"` - exit if not found
2. **Invoke Prepare_Book skill**: Handles TOC analysis, PDF splitting, markdown conversion
3. **Read toc.json**: Understand book structure for orchestration
4. **Set variables immediately after reading toc.json**:
```bash
# Extract from toc.json's pdf_path or the "Ï†ÄÏû•Îê®:" output path
VAULT_PATH="/Users/seongjin/Documents/‚≠êÏÑ±ÏßÑÏù¥Ïùò ÏòµÏãúÎîîÏñ∏"
BOOK_FOLDER="/absolute/path/to/book_folder"  # e.g., from toc.json location
BOOK_NAME="book_name"  # basename of BOOK_FOLDER
```

**Output structure**:
```
{book_name}/
	toc.json, {chapter}.pdf, {chapter}.md, image-cache_{chapter}.json, images/
```

### Phase 1.5: Image Description

**Single Bash() call** with sequential processing (special characters safe):
```bash
find "$BOOK_FOLDER" -maxdepth 1 -name "*.md" -type f -not -name "*.backup*" -print0 | \
	sort -zV | while IFS= read -r -d '' file; do
		echo "Processing: $file"
		(cd "$VAULT_PATH/.claude/skills/Describe_Images/Scripts" && \
			source .venv/bin/activate && \
			python Describe_Images.py "$file")
	done
```

- Uses `-print0` and `read -d ''` for special character safety (`"`, `'` in filenames)
- Sequential processing prevents API rate limit issues
- Subshell `(...)` preserves working directory

### Phase 2: Content Restructuring

**Single Bash() call** with batch script (10-second intervals for API rate limit):
```bash
"$VAULT_PATH/.claude/skills/Restructure/scripts/batch.sh" "$BOOK_FOLDER" "{additional_prompt}"
```
- **Use `$VAULT_PATH` and `$BOOK_FOLDER` variables** (set in Phase 1)
- Processes files in ascending filename order (`sort -V`)
- 10-second delay between files prevents API rate limit
- Optional: pass additional prompt as second argument

**Output**: `Restructured_{chapter}.md` (auto-generated by script)

### Phase 2.1: Restructuring Validation

**Goal**: Detect chapters where Gemini abnormally truncated content.

**Method**: Compare character counts between original `{chapter}.md` and `Restructured_{chapter}.md`, print comparison table:

| # | Chapter | Original (chars) | Restructured (chars) | Ratio |
|---|---------|------------------:|---------------------:|------:|

- **Threshold**: ratio < 35% ‚Üí abnormal (normal range ~45-55%)
- **Anomaly detected** ‚Üí `AskUserQuestion()` to confirm reprocessing flagged chapters
  - If approved: re-run `restructure.sh` per flagged file (10s intervals) ‚Üí re-validate
- **No anomalies** ‚Üí proceed to Phase 2.5

### Phase 2.5: Heading Normalization

**Goal**: Normalize heading hierarchy, replace first heading with toc title, add ancestor headings for first children.

#### Level Normalization (required for all books)

Gemini outputs inconsistent heading levels per file. Always normalize:

1. **First heading level = split level**
   - split --level 1 ‚Üí first heading = `#` (h1)
   - split --level 2 ‚Üí first heading = `##` (h2)
   - split --level 3 ‚Üí first heading = `###` (h3)
2. **First heading title = toc.json entry title** for that file
3. **Remaining headings must be deeper than first heading by at least one level**
   - shift = min(remaining heading levels) - (split_level + 1)
   - new_level = old_level - shift (floor = split_level + 1)
4. **Preserve relative depth**: depth differences between headings within a file are maintained

Code pattern:
```python
split_level = 1  # from Prepare_Book --level argument
for each Restructured file:
    first_heading ‚Üí "#" * split_level + " " + toc_title
    other_headings:
        target_min = split_level + 1  # e.g., 2 for split_level=1
        actual_min = min(other heading levels)
        shift = actual_min - target_min
        new_level = old_level - shift (min = target_min)
```

#### Ancestor Heading Algorithm

1. **Parse toc.json** ‚Üí build parent-child relationships
2. **First child detection**: Entry is first child if it's the first at that level after parent
3. **Ancestor chain**: If first child, trace upward collecting ancestors (also first children)
4. **Per-file normalization**:
	- Add ancestor headings (e.g., `# Part I` before `## 3. Chapter Title`)
	- First heading = `{#level} {toc_title}`
	- Subsequent headings deeper than first

**Example** (split at level=2):
```
Part I (level 1) ‚Üê parent
	‚îú‚îÄ 3. One Person's... (level 2) ‚Üê FIRST CHILD ‚Üí prepend "# Part I"
	‚îî‚îÄ 4. Another Chapter (level 2) ‚Üê not first child
```

Result for `Restructured_3. One Person's...md`:
```markdown
# Part I: Liberty and Freedom

## 3. One Person's Freedom Is Another Person's Unfreedom
```

**Execution Method**: Use `Bash()` with heredoc - NO temporary py files
```bash
python3 << 'EOF'
import json, glob, re
# LLM generates situation-specific code here
# ... toc parsing, file matching, heading normalization ...
EOF
```
- DO NOT create temporary .py files
- Write Python code directly inside Bash() heredoc
- LLM adapts code to each book's specific structure

### Phase 3: Merge

1. **Find files**: `find "$BOOK_FOLDER" -maxdepth 1 -name "Restructured_*.md" | sort -V`
2. **Merge with Python**: glob ‚Üí numeric sort ‚Üí join with 5 blank lines
3. **Output**: `$BOOK_FOLDER/Merge_$BOOK_NAME.md`
- **Use `$BOOK_FOLDER` and `$BOOK_NAME` variables** (set in Phase 1)

### Phase 4: Results Summary

Output markdown summary: source PDF, chapters processed, file mapping, merged document path.

---

## Critical Constraints

These constraints prevent unrecoverable errors:

1. **Main command MUST NOT Read() markdown files** - only toc.json allowed
2. **Rate-limited batch processing** - use batch.sh with 10-second delays for API rate limit
3. **NEVER use `$(pwd)` or relative paths** - working directory may be polluted; always use `$VAULT_PATH`, `$BOOK_FOLDER`, `$BOOK_NAME` variables set in Phase 1
4. **Use `-print0 | while read -d ''`** for file iteration - handles special characters (`"`, `'`) in filenames safely
5. **Wait for Bash() completion** before next phase - file existence ‚â† content complete
6. **Use Python file I/O** - macOS unicode (NFC vs NFD) breaks Edit tool on Korean paths
7. **Use `sort -V`** for file ordering - alphabetic sort puts "10" before "2"
8. **No AskUserQuestion at completion** - user provides feedback if needed (Phase 2.1 validation is the only exception where `AskUserQuestion()` is used)

---

## Error Handling

| Error | Solution |
|-------|----------|
| Source PDF not found | Verify path with `ls` |
| No TOC in PDF | PDF needs embedded TOC (Adobe Acrobat) |
| Markdown conversion failed | Check TMP/PDF_to_MD/.env API keys |
| Restructuring failed | Check `which gemini`, API quota, UTF-8 encoding |
| venv issues | `rm -rf venv && python3 -m venv venv && pip install -r requirements.txt` |

---

## Quick Reference

| Scenario | Command |
|----------|---------|
| Full processing | `/Book TMP/Value.pdf` |
| Korean style | `/Book TMP/Book.pdf "Korean informal style"` |
| Custom style | `/Book TMP/Book.pdf "academic formal style"` |

**Output Structure**:
```
{book_name}/
	toc.json
	{chapter}.pdf / .md / image-cache_{chapter}.json
	Restructured_{chapter}.md
	Merge_{book_name}.md
	images/
```

---

## Version History

**v1.7.0** (2026-02-13)
- Added Phase 2.1: Restructuring Validation
- Compares Original vs Restructured character counts, prints comparison table
- Flags chapters below 35% ratio as abnormal (normal range ~45-55%)
- Uses `AskUserQuestion()` to confirm reprocessing of flagged chapters
- Updated Critical Constraint #8 to allow AskUserQuestion in Phase 2.1 only

**v1.6.9** (2026-01-31)
- Phase 2.5: Added explicit Level Normalization rules (split_level ‚Üí first heading, shift remaining headings)
- Prevents inconsistent heading levels from Gemini output without manual correction passes

**v1.6.8** (2026-01-28)
- Phase 1.5: Changed to sequential processing with `find -print0 | while read -d ''`
- Fixes special character handling (`"`, `'`) in filenames that broke parallel Bash() calls
- Single Bash() call instead of multiple parallel calls

**v1.6.7** (2026-01-28)
- Phase 1.5: Changed to two-step execution (list files ‚Üí parallel Bash() per file)
- Removed fragile shell pipeline with subshell, grep, xargs
- Better error isolation and progress visibility
- Updated Critical Constraints: removed subshell requirement

**v1.6.6** (2026-01-28)
- Added "Variable Definitions" section with `VAULT_PATH`, `BOOK_FOLDER`, `BOOK_NAME`
- Phase 1: Added step 4 to set variables immediately after reading toc.json
- All phases now use explicit variable names instead of `{placeholder}` syntax
- Critical Constraints: Added explicit `$(pwd)` prohibition, renumbered constraints

**v1.6.5** (2026-01-27)
- Phase 2: Changed from parallel Bash() to single batch.sh call (10-second intervals)

**v1.6.4** (2026-01-27)
- Phase 2.5: Use Bash() heredoc (no temporary py files), removed pseudo code for LLM flexibility

**v1.6.3** (2026-01-27)
- Phase 2: Changed from `xargs -P 3` to individual Bash() parallel calls (one file per Bash)

**v1.6.2** (2026-01-27)
- Fixed working directory issue: Phase 1.5 uses subshell `(...)` to prevent `cd` pollution
- Phase 2 now uses absolute path `{vault_path}/.claude/skills/...`
- Reduced `-P 5` to `-P 3` to prevent Gemini API rate limit exhaustion

**v1.6.1** (2026-01-27)
- Changed parallel execution from multiple Bash() calls to single Bash() with `xargs -P 5`
- Shell-level parallelism: 5 files processed at a time (prevents API rate limit)

**v1.6.0** (2026-01-19)
- Added ancestor heading insertion for first children in Phase 2.5
- Chain detection: if parent is also first child, grandparent added too

**v1.5.2**: First heading title replacement with exact toc.json title
**v1.5.1**: Per-file toc level matching (not global level)
**v1.5.0**: Added Merge phase with `sort -V` ordering
**v1.4.0**: Sequential ‚Üí Parallel execution for restructuring
**v1.3.1**: Python file I/O for macOS unicode, heading pattern docs

---

## Execution Directive

Execute immediately in sequence:

1. Parse `$ARGUMENTS` ‚Üí source PDF path + optional instructions
2. Verify PDF exists (`ls`)
3. Invoke Prepare_Book skill, wait for completion
4. Read toc.json (only file to read directly)
5. **Set variables immediately** (CRITICAL - before any subsequent phase):
```bash
VAULT_PATH="/Users/seongjin/Documents/‚≠êÏÑ±ÏßÑÏù¥Ïùò ÏòµÏãúÎîîÏñ∏"
BOOK_FOLDER="<absolute path from toc.json location>"
BOOK_NAME="<basename of BOOK_FOLDER>"
```
6. Phase 1.5: Single Bash() with `find -print0 | while read` for sequential processing
7. Phase 2: Single Bash() with batch.sh using `$VAULT_PATH` and `$BOOK_FOLDER`
8. Phase 2.1: Validation table ‚Üí if anomalies, `AskUserQuestion()` ‚Üí reprocess flagged chapters
9. Phase 2.5: Heading normalization with Python heredoc using `$BOOK_FOLDER`
10. Phase 3: Merge with Python using `$BOOK_FOLDER` and `$BOOK_NAME`
11. Output results summary (no AskUserQuestion)